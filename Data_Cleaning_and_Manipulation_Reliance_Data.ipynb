{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', 'Data_Cleaning_and_Manipulation_Reliance_Data.ipynb', 'Resources']\n",
      "['reliance_data.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List all files in the current directory\n",
    "print(os.listdir())\n",
    "\n",
    "# List all files in the 'Resources' directory\n",
    "print(os.listdir('Resources'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date    Symbol Series  Prev Close    Open    High     Low  Last  \\\n",
      "0  01-01-1996  RELIANCE     EQ      204.65  205.00  206.10  203.65   NaN   \n",
      "1  02-01-1996  RELIANCE     EQ      205.75  205.25  206.25  202.65   NaN   \n",
      "2  03-01-1996  RELIANCE     EQ      204.15  207.50  216.95  205.25   NaN   \n",
      "3  04-01-1996  RELIANCE     EQ      205.70  203.75  204.40  201.05   NaN   \n",
      "4  05-01-1996  RELIANCE     EQ      203.80  203.00  203.00  200.65   NaN   \n",
      "\n",
      "    Close    VWAP   Volume      Turnover  Trades  Deliverable Volume  \\\n",
      "0  205.75  205.26  3717450  7.630000e+13     NaN                 NaN   \n",
      "1  204.15  204.13  6024650  1.230000e+14     NaN                 NaN   \n",
      "2  205.70  207.04  7473500  1.550000e+14     NaN                 NaN   \n",
      "3  203.80  202.47  7744000  1.570000e+14     NaN                 NaN   \n",
      "4  202.40  202.05  5952000  1.200000e+14     NaN                 NaN   \n",
      "\n",
      "   %Deliverble  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "stock_data = pd.read_csv('Resources/reliance_data.csv')\n",
    "print(stock_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                     0\n",
      "Symbol                   0\n",
      "Series                   0\n",
      "Prev Close               0\n",
      "Open                     0\n",
      "High                     0\n",
      "Low                      0\n",
      "Last                   548\n",
      "Close                    0\n",
      "VWAP                     0\n",
      "Volume                   0\n",
      "Turnover                 0\n",
      "Trades                3849\n",
      "Deliverable Volume    1512\n",
      "%Deliverble           1512\n",
      "dtype: int64\n",
      "Date                  0\n",
      "Symbol                0\n",
      "Series                0\n",
      "Prev Close            0\n",
      "Open                  0\n",
      "High                  0\n",
      "Low                   0\n",
      "Last                  0\n",
      "Close                 0\n",
      "VWAP                  0\n",
      "Volume                0\n",
      "Turnover              0\n",
      "Trades                0\n",
      "Deliverable Volume    0\n",
      "%Deliverble           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "# Check for missing values\n",
    "print(stock_data.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values\n",
    "stock_data.dropna(inplace=True)\n",
    "print(stock_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"13-06-2011\" doesn't match format \"%m-%d-%Y\", at position 8. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert 'Date' column to datetime format\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m stock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Sort the data by date\u001b[39;00m\n\u001b[0;32m      5\u001b[0m stock_data\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ayeni\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1112\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1111\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1113\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\Users\\ayeni\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    491\u001b[0m     arg,\n\u001b[0;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m )\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ayeni\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    509\u001b[0m     arg,\n\u001b[0;32m    510\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[1;32mstrptime.pyx:534\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:355\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"13-06-2011\" doesn't match format \"%m-%d-%Y\", at position 8. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# Convert 'Date' column to datetime format\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "\n",
    "# Sort the data by date\n",
    "stock_data.sort_values(by='Date', inplace=True)\n",
    "print(stock_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date    Symbol Series  Prev Close    Open    High     Low  Last  \\\n",
      "0 1996-01-01  RELIANCE     EQ      204.65  205.00  206.10  203.65   NaN   \n",
      "1 1996-01-02  RELIANCE     EQ      205.75  205.25  206.25  202.65   NaN   \n",
      "2 1996-01-03  RELIANCE     EQ      204.15  207.50  216.95  205.25   NaN   \n",
      "3 1996-01-04  RELIANCE     EQ      205.70  203.75  204.40  201.05   NaN   \n",
      "4 1996-01-05  RELIANCE     EQ      203.80  203.00  203.00  200.65   NaN   \n",
      "\n",
      "    Close    VWAP   Volume      Turnover  Trades  Deliverable Volume  \\\n",
      "0  205.75  205.26  3717450  7.630000e+13     NaN                 NaN   \n",
      "1  204.15  204.13  6024650  1.230000e+14     NaN                 NaN   \n",
      "2  205.70  207.04  7473500  1.550000e+14     NaN                 NaN   \n",
      "3  203.80  202.47  7744000  1.570000e+14     NaN                 NaN   \n",
      "4  202.40  202.05  5952000  1.200000e+14     NaN                 NaN   \n",
      "\n",
      "   %Deliverble  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "stock_data = pd.read_csv('Resources/reliance_data.csv')\n",
    "\n",
    "# Convert 'Date' column to datetime format specifying the correct format\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'], format='%d-%m-%Y')\n",
    "\n",
    "# Sort the data by date\n",
    "stock_data.sort_values(by='Date', inplace=True)\n",
    "\n",
    "print(stock_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by date\n",
    "stock_data.sort_values(by='Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for and remove duplicate rows\n",
    "stock_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types After Conversion:\n",
      "Date                  datetime64[ns]\n",
      "Symbol                        object\n",
      "Series                        object\n",
      "Prev Close                   float64\n",
      "Open                         float64\n",
      "High                         float64\n",
      "Low                          float64\n",
      "Last                         float64\n",
      "Close                        float64\n",
      "VWAP                         float64\n",
      "Volume                         int64\n",
      "Turnover                     float64\n",
      "Trades                       float64\n",
      "Deliverable Volume           float64\n",
      "%Deliverble                  float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Ensure all columns have appropriate data types\n",
    "print(\"\\nData Types After Conversion:\")\n",
    "print(stock_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect and handle outliers (simple approach: clipping)\n",
    "# Assuming 'Close' column represents the closing stock price\n",
    "q_low = stock_data['Close'].quantile(0.01)\n",
    "q_high = stock_data['Close'].quantile(0.99)\n",
    "stock_data = stock_data[(stock_data['Close'] >= q_low) & (stock_data['Close'] <= q_high)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with NaN values that might have been introduced by pct_change\n",
    "stock_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Data:\n",
      "           Date    Symbol Series  Prev Close    Open    High     Low   Last  \\\n",
      "3849 2011-06-01  RELIANCE     EQ      951.85  952.00  958.65  943.65  947.5   \n",
      "3850 2011-06-02  RELIANCE     EQ      946.80  936.55  954.70  936.55  952.5   \n",
      "3851 2011-06-03  RELIANCE     EQ      951.05  960.50  967.00  931.50  936.0   \n",
      "3852 2011-06-06  RELIANCE     EQ      934.60  934.65  940.80  928.15  938.6   \n",
      "3853 2011-06-07  RELIANCE     EQ      937.75  933.55  960.00  933.55  959.6   \n",
      "\n",
      "       Close    VWAP   Volume      Turnover    Trades  Deliverable Volume  \\\n",
      "3849  946.80  947.83  1838452  1.740000e+14   58630.0            901415.0   \n",
      "3850  951.05  947.09  2152963  2.040000e+14   63061.0           1066759.0   \n",
      "3851  934.60  951.69  4368279  4.160000e+14  128784.0           1035791.0   \n",
      "3852  937.75  935.29  1405741  1.310000e+14   43384.0            476631.0   \n",
      "3853  958.25  950.55  4025919  3.830000e+14   88703.0           2424958.0   \n",
      "\n",
      "      %Deliverble  \n",
      "3849       0.4903  \n",
      "3850       0.4955  \n",
      "3851       0.2371  \n",
      "3852       0.3391  \n",
      "3853       0.6023  \n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned data\n",
    "print(\"\\nCleaned Data:\")\n",
    "print(stock_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned data saved to Resources/cleaned_reliance_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned data to a new CSV file \n",
    "cleaned_data_path = 'Resources/cleaned_reliance_data.csv'\n",
    "stock_data.to_csv(cleaned_data_path, index=False)\n",
    "print(f\"\\nCleaned data saved to {cleaned_data_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
